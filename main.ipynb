{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from params import ParamsKITTI, ParamsEuroc\n",
    "from dataset import KITTIOdometry, EuRoCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/David/miniconda3/envs/dev/bin/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[ 1  2  3  4  5  6]\n",
      " [ 2  4  6  8 10 12]\n",
      " [ 3  6  9 12 15 18]]\n",
      "mask:\n",
      " [False  True  True False  True False]\n",
      "mask2:\n",
      " [0 1 1 0 1 0]\n",
      "a[:, mask] (WORKS):\n",
      " [[ 2  3  5]\n",
      " [ 4  6 10]\n",
      " [ 6  9 15]]\n",
      "a[:, mask2]:\n",
      " [[ 2  3  5]\n",
      " [ 4  6 10]\n",
      " [ 6  9 15]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2,3,4,5,6],[2,4,6,8,10,12],[3,6,9,12,15,18]])\n",
    "mask2=np.zeros((6,), dtype=int)\n",
    "mask2[1] = 1\n",
    "mask2[2] = 1\n",
    "mask2[4] = 1\n",
    "\n",
    "mask = np.array([False, True, True, False, True, False])\n",
    "\n",
    "print(\"a:\\n\", a)\n",
    "print(\"mask:\\n\", mask)\n",
    "print(\"mask2:\\n\", mask2)\n",
    "print(\"a[:, mask] (WORKS):\\n\", a[:, mask])\n",
    "print(\"a[:, mask2]:\\n\", a[:, mask2.astype(bool)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroundTruthLoader:\n",
    "    def __init__(self, path, dataset, start_idx, end_idx):\n",
    "        self.traj = []\n",
    "        start_ts = dataset.timestamps[start_idx] # timestamp of first frame to consider\n",
    "        end_ts = dataset.timestamps[end_idx] # timestamp of last frame to consider\n",
    "\n",
    "        has_first_row = False\n",
    "        with open(path, newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader) # skip header\n",
    "            for row in csv_reader:\n",
    "                if float(row[0])/1e9 > end_ts:\n",
    "                    break\n",
    "                if float(row[0])/1e9 >= start_ts:\n",
    "                    if not has_first_row:\n",
    "                        ref = np.array([float(row[1]), float(row[2]), float(row[3])])\n",
    "                        has_first_row = True\n",
    "                    self.traj.append(np.array([float(row[1]), float(row[2]), float(row[3])]))\n",
    "                    self.traj[-1] = self.traj[-1] - ref\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_FRAME = 0\n",
    "SECOND_FRAME = 1\n",
    "DEFAULT = 2\n",
    "\n",
    "class VO:\n",
    "    def __init__(self, path, cam, start_idx=0):\n",
    "        self.stage = FIRST_FRAME\n",
    "        self.curr_idx = start_idx\n",
    "        self.num_processed = 0\n",
    "        \n",
    "        # dataset-dependent params\n",
    "        self.params = ParamsEuroc()\n",
    "        self.dataset = EuRoCDataset(path)\n",
    "        \n",
    "        self.detector = cv2.ORB_create(nfeatures=200, scaleFactor=1.2, nlevels=1, edgeThreshold=31)\n",
    "        self.ffdetector = cv2.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)\n",
    "        self.extractor = cv2.xfeatures2d.BriefDescriptorExtractor_create(bytes=32, use_orientation=False)\n",
    "        self.bf_matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "        \n",
    "        # kpts and descriptors of all frames seen so far\n",
    "        self.kpts = []\n",
    "        self.des = []\n",
    "        self.matches = []\n",
    "        \n",
    "        # params for Shi-Tomasi corner detection\n",
    "        self.detector_params = dict(maxCorners = 150,\n",
    "                              qualityLevel = 0.3,\n",
    "                              minDistance = 7,\n",
    "                              blockSize = 7)\n",
    "\n",
    "        # tracker params\n",
    "        self.tracker_params = dict(winSize = (21, 21),\n",
    "                                   criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "        \n",
    "        # hash table to find 3d points across frames\n",
    "        #self.pts_3d = {}\n",
    "        self.pts_3d = []\n",
    "        self.good_idxs = []\n",
    "        \n",
    "        # relevant images seen so far\n",
    "        self.prev_img = self.dataset.left[start_idx]\n",
    "        self.curr_img = self.dataset.left[start_idx]\n",
    "        \n",
    "        # camera model\n",
    "        self.f = (cam.fx + cam.fy) / 2 # avg of both focal lengths\n",
    "        self.pp = (cam.cx, cam.cy)\n",
    "        self.K = np.append(cam.intrinsic_matrix, np.array([[0, 0, 0]]).T, axis=1) # 3x4 ndarray\n",
    "        \n",
    "        # trajectory\n",
    "        self.poses = []\n",
    "        \n",
    "        self.viz = True\n",
    "        self.tracks = []\n",
    "            \n",
    "    def update(self):\n",
    "        #print(\"INFO: in update()\")\n",
    "        self.timestamp = self.dataset.timestamps[self.curr_idx]\n",
    "        self.prev_img = self.curr_img\n",
    "        self.curr_img = self.dataset.left[self.curr_idx]\n",
    "        \n",
    "        if self.stage == FIRST_FRAME:\n",
    "            self.process_first_frame()\n",
    "        elif self.stage == SECOND_FRAME:\n",
    "            self.process_second_frame()\n",
    "        else:\n",
    "            self.process_default()\n",
    "        \n",
    "        if self.viz:\n",
    "            self.draw()\n",
    "            \n",
    "        self.curr_idx = self.curr_idx + 1\n",
    "        self.num_processed = self.num_processed + 1\n",
    "    \n",
    "    def draw(self):\n",
    "        vis = self.curr_img.copy()\n",
    "        if len(self.tracks) > 0:\n",
    "            print(\"THERE ARE TRACKS\")\n",
    "            new_tracks = []\n",
    "            for tr, (x, y), good_flag in zip(self.tracks, self.kpts[-1].reshape(-1, 2), self.good):\n",
    "                if not good_flag:\n",
    "                    continue\n",
    "                tr.append((x, y))\n",
    "                new_tracks.append(tr)\n",
    "                cv2.circle(vis, (x, y), 2, (0, 255, 0), -1)\n",
    "            self.tracks = new_tracks\n",
    "            cv2.polylines(vis, [np.int32(tr) for tr in self.tracks], False, (0, 255, 0))\n",
    "        else:\n",
    "            for x, y in [np.int32(tr[-1]) for tr in self.tracks]:\n",
    "                cv2.circle(vis, (x, y), 5, 0, -1)\n",
    "            if self.kpts[-1] is not None:\n",
    "                for x, y in np.float32(self.kpts[-1]).reshape(-1, 2):\n",
    "                    self.tracks.append([(x, y)])\n",
    "                    print(x, y)\n",
    "        plt.imshow(vis, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    def track_features(self, kpts_prev=None):\n",
    "        if kpts_prev is None:\n",
    "            kpts_prev = self.kpts[-1]\n",
    "        print(\"in track_features... in:\", len(self.kpts[-1]))\n",
    "        #kpts_prev = self.kpts[-1]\n",
    "        kpts, st, err = cv2.calcOpticalFlowPyrLK(self.prev_img, self.curr_img, kpts_prev, None, **(self.tracker_params))\n",
    "        #status = st.reshape(st.shape[0])\n",
    "        #self.good_trks = st == 1\n",
    "        #self.kpts[-1] = kpts_prev[st == 1]\n",
    "        #kpts = kpts[st == 1]\n",
    "        #print(\"in track_features... out:\", len(kpts))\n",
    "        kpts_r, _st, _err = cv2.calcOpticalFlowPyrLK(self.curr_img, self.prev_img, kpts, None, **(self.tracker_params))\n",
    "        d = abs(kpts - kpts_r).reshape(-1, 2).max(-1)\n",
    "        self.good = d < 1\n",
    "        return kpts\n",
    "\n",
    "    def process_first_frame(self):\n",
    "        print(\"\\nINFO: in process_first_frame()\")\n",
    "        #kpts, des = self.detector.detectAndCompute(self.curr_img, None)\n",
    "        #kpts = self.ffdetector.detect(self.curr_img)\n",
    "        kpts = cv2.goodFeaturesToTrack(self.curr_img, mask = None, **self.detector_params)\n",
    "        print(len(kpts))\n",
    "        R = np.array([[1.0, 0, 0],\n",
    "                      [0, 1.0, 0],\n",
    "                      [0, 0, 1.0]]) # rotation matrix\n",
    "        t = np.array([0, 0, 0]) # translation vector\n",
    "        self.poses.append((R, t))\n",
    "        self.kpts.append(np.asarray(kpts))\n",
    "        #self.des.append(des)\n",
    "        self.stage = SECOND_FRAME\n",
    "\n",
    "    def process_second_frame(self):\n",
    "        print(\"\\nINFO: in process_second_frame()\")\n",
    "\n",
    "        '''\n",
    "        DEPRECATED:\n",
    "        \n",
    "        kpts, des = self.detector.detectAndCompute(self.curr_img, None)\n",
    "                \n",
    "        # match\n",
    "        matches = self.bf_matcher.knnMatch(self.des[-1], des, k=2)\n",
    "        pts1 = []\n",
    "        pts2 = []\n",
    "        good = []\n",
    "        idxs = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.5 * n.distance:\n",
    "                pts1.append(self.kpts[-1][m.queryIdx].pt)\n",
    "                pts2.append(kpts[m.trainIdx].pt)\n",
    "                good.append([m])\n",
    "                idxs.append(m.trainIdx)\n",
    "        print(\"{} good matches out of {} total keypoints in frame {}\"\n",
    "              .format(len(pts2), len(kpts), self.num_processed + 1))\n",
    "        '''\n",
    "\n",
    "        kpts = self.track_features()\n",
    "        \n",
    "        # extract relative pose\n",
    "        E, mask = cv2.findEssentialMat(np.array(self.kpts[-1]), np.array(kpts), focal=self.f, pp=self.pp, method=cv2.RANSAC, prob=0.99, threshold=0.5)\n",
    "        _, R, t, _ = cv2.recoverPose(E, np.array(self.kpts[-1]), np.array(kpts), focal=self.f, pp=self.pp)\n",
    "        #print(\"Essential matrix:\", E)\n",
    "        \n",
    "        # triangulate points from two views (current and previous)\n",
    "        pts_3d, idxs = self.triangulate_points(R, t, self.kpts[-1], kpts) # np.array, 3xN\n",
    "        #print(\"{} points triangulated\".format(pts_3d.shape[1]), pts_3d)\n",
    "        \n",
    "        # insert elements into hash table\n",
    "        #self.populate_idx_to_pts3d(idxs, pts_3d.T)\n",
    "        \n",
    "        # compute absolute pose\n",
    "        R = R.dot(self.poses[-1][0])\n",
    "        t = R.dot(self.poses[-1][1]) + t[:,0]\n",
    "        \n",
    "        # bookkeep\n",
    "        #print(pts_3d[:,:5])\n",
    "        #print(pts2[:5])\n",
    "        #print(\"rotation:\", R)\n",
    "        print(\"translation:\", t)\n",
    "        \n",
    "        self.good_idxs.append(np.asarray(idxs))\n",
    "        self.pts_3d.append(pts_3d)\n",
    "        \n",
    "        self.poses.append((R, t))\n",
    "        self.kpts.append(np.array(kpts))\n",
    "        #self.des.append(des)\n",
    "        #self.matches.append(good)\n",
    "        self.stage = DEFAULT\n",
    "    \n",
    "    def process_default(self):\n",
    "        print(\"\\nINFO: in process_default()\")\n",
    "        '''\n",
    "        # detect and extract TODO: change to use KLT tracking\n",
    "        kpts, des = self.detector.detectAndCompute(self.curr_img, None)\n",
    "        \n",
    "        # match\n",
    "        matches = self.bf_matcher.knnMatch(self.des[-1], des, k=2)\n",
    "        pts1 = []\n",
    "        pts2 = []\n",
    "        good = []\n",
    "        pts_3d = []\n",
    "        pts_2d = []\n",
    "        idxs = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.5 * n.distance:\n",
    "                pts1.append(self.kpts[-1][m.queryIdx].pt)\n",
    "                pts2.append(kpts[m.trainIdx].pt)\n",
    "                good.append([m])\n",
    "                idxs.append(m.trainIdx)\n",
    "                if m.queryIdx in self.pts_3d:\n",
    "                    pts_2d.append(self.kpts[-1][m.queryIdx].pt)\n",
    "                    pts_3d.append(self.pts_3d[m.queryIdx])\n",
    "        print(\"{} good matches out of {} total keypoints in frame {}\"\n",
    "              .format(len(pts2), len(kpts), self.num_processed + 1))        \n",
    "\n",
    "        '''\n",
    "        # track from previous to current frame\n",
    "        #kpts = self.track_features(self.kpts[-1][self.good_idxs[-1]])\n",
    "        kpts = self.track_features()\n",
    "        \n",
    "        '''\n",
    "        print(self.pts_3d[-1])\n",
    "        _, rot, t, inliers = cv2.solvePnPRansac(np.asarray(self.pts_3d[-1][self.good_trks]), np.asarray(kpts), \n",
    "                                                    self.K[:,:3], None, None, None, False, 50, 2.0, 0.9, None)\n",
    "        \n",
    "        \n",
    "        # make sure we can proceed\n",
    "        if inliers is None or len(inliers) < 5:\n",
    "            print(\"ERROR -- failed to solve PnP... skipping frame\")\n",
    "            return\n",
    "        \n",
    "        print(\"num total pts:\", len(pts_3d), \"num inliers:\", len(inliers))\n",
    "        R = cv2.Rodrigues(rot)[0]\n",
    "        \n",
    "        # triangulate points from two views (current and previous)\n",
    "        pts_3d, idxs = self.triangulate_points(R, t, self.kpts[-1], kpts) # np.array, 3xN\n",
    "        print(\"{} points triangulated\".format(pts_3d.shape[1]))\n",
    "        \n",
    "        # insert elements into hash table\n",
    "        self.populate_idx_to_pts3d(idxs, pts_3d.T)\n",
    "        \n",
    "        # compute absolute pose\n",
    "        R = R.dot(self.poses[-1][0])\n",
    "        t = R.dot(self.poses[-1][1]) + t[:,0]\n",
    "        '''\n",
    "        \n",
    "        # bookkeep\n",
    "        #print(\"rotation:\", R)\n",
    "        #print(\"translation:\", t)\n",
    "        #self.poses.append((R, t))\n",
    "        self.kpts.append(kpts)\n",
    "        #self.des.append(des)\n",
    "        #self.matches.append(good)\n",
    "        \n",
    "    '''\n",
    "    def populate_idx_to_pts3d(self, idxs, pts_3d):\n",
    "        if (pts_3d.shape[0] == 3):\n",
    "            pts_3d = pts_3d.T\n",
    "        if (pts_3d.shape[0] != len(idxs)):\n",
    "            print(\"FATAL -- {} vs {}\".format(pts_3d.shape[0], len(idxs))) # TODO exit here\n",
    "        \n",
    "        self.pts_3d.clear()\n",
    "        for idx, p in zip(idxs, pts_3d):\n",
    "            if idx in self.pts_3d:\n",
    "                print(\"duplicated idx!!!\")\n",
    "            self.pts_3d[idx] = p\n",
    "        print(\"{} elements in hash table\".format(len(self.pts_3d)))\n",
    "    ''' \n",
    "    def triangulate_points(self, R, t, kpts1, kpts2):\n",
    "        P_1 = self.K.dot(np.linalg.inv(self.T_from_Rt(R, t)))\n",
    "        P_2 = self.K # assume camera 2 is at origin\n",
    "        \n",
    "        pts_hom = cv2.triangulatePoints(P_1, P_2, np.asarray(kpts1).T, np.asarray(kpts2).T) # in homogeneous coords\n",
    "        pts = pts_hom / np.tile(pts_hom[-1, :], (4, 1)) # 4xN\n",
    "        good_idxs = (pts[3,:] > 0) & (np.abs(pts[2, :]) > 0.01)\n",
    "        #print(np.array(pts.T[good_idxs]).T.shape)\n",
    "        #print(len(good_idxs), \"good indices\")\n",
    "        #print(np.array(pts[:3,good_idxs]).shape)\n",
    "        return np.array(pts[:3, good_idxs]), good_idxs[0] # 3xM, where M = len(good_idxs)\n",
    "        \n",
    "    def draw_matches(self):\n",
    "        plt.ion() # interactive\n",
    "        if self.stage == DEFAULT:\n",
    "            img_matches = cv2.drawMatchesKnn(self.prev_image, self.prev_kpts, self.curr_image,\n",
    "                                             self.curr_kpts, self.matches[-1], None, \n",
    "                                             flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "            plt.figure(figsize=(12,8), dpi=100)\n",
    "            plt.imshow(img_matches)\n",
    "            plt.show()\n",
    "            input(\"press any key\")\n",
    "    \n",
    "    def T_from_Rt(self, R, t):\n",
    "        t = t.reshape((3, 1))\n",
    "        R = R.reshape((3, 3))\n",
    "        return np.append(np.append(R, t, axis=1), np.array([[0,0,0,1]]), axis=0)\n",
    "    \n",
    "    def get_image(self, idx):\n",
    "        idx = max(0, idx)\n",
    "        return self.dataset.left[idx]\n",
    "    \n",
    "    @property\n",
    "    def curr_image(self):\n",
    "        return self.curr_img\n",
    "    \n",
    "    @property\n",
    "    def curr_kpts(self):\n",
    "        if len(self.kpts) > 0:\n",
    "            return self.kpts[-1]\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    @property\n",
    "    def prev_image(self):\n",
    "        return self.prev_img\n",
    "    \n",
    "    @property\n",
    "    def prev_kpts(self):\n",
    "        if len(self.kpts) > 1:\n",
    "            print(\"len(self.kpts):\", len(self.kpts))\n",
    "            return self.kpts[-2]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ground truth loader object\n",
    "ground_truth_path = os.path.join(path, 'mav0/state_groundtruth_estimate0/data.csv')\n",
    "gtloader = GroundTruthLoader(ground_truth_path, dataset, start_idx, start_idx+frames_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create VO object\n",
    "path = '/Users/David/Downloads'\n",
    "start_idx = 400\n",
    "frames_to_process = 1000\n",
    "dataset = EuRoCDataset(path)\n",
    "vo = VO(path, dataset.left_cam, start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "idx = 120\n",
    "plt.ion()\n",
    "for i in range(390, 420):\n",
    "    plt.figure()\n",
    "    plt.imshow(vo.get_image(i), cmap='gray')\n",
    "    plt.show()\n",
    "    input(\"press any key\")\n",
    "    #print(vo.dataset.timestamps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# main loop\n",
    "for i in range(1, 10):#frames_to_process + 1):\n",
    "    print(\"INFO: images\", i-1, \"-\", i)\n",
    "    vo.update()\n",
    "    #vo.draw_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = vo.curr_img\n",
    "cv2.circle(img, (200,300), 20, (0, 255, 0), 2)\n",
    "cv2.imshow('something', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "# why again??\n",
    "\n",
    "plot_ground_truth = False\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "zs = []\n",
    "for r, t in vo.poses:\n",
    "    xs.append(t[0])\n",
    "    ys.append(t[1])\n",
    "    zs.append(t[2])\n",
    "\n",
    "xs_t = []\n",
    "ys_t = []\n",
    "zs_t = []\n",
    "for pt in gtloader.traj:\n",
    "    xs_t.append(pt[0])\n",
    "    ys_t.append(pt[1])\n",
    "    zs_t.append(pt[2])\n",
    "    \n",
    "ax.plot(xs, ys, zs, label='Estimated 3D trajectory')\n",
    "if plot_ground_truth:\n",
    "    ax.plot(xs_t, ys_t, zs_t, label='Ground truth')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
